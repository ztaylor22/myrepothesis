---
title: "ThesisDataWrangling"
output:
  pdf_document: default
  html_document: default
date: '2022-10-10'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse=TRUE, prompt=TRUE, eval=TRUE, message=F, include=T,comment=NULL, fig.height = 4, fig.width = 8)
```

```{r packageCheck, include=FALSE}
mypacks <- c("timetk","dplyr","tidyverse","ggplot2","tidyr","lubridate","quantmod","viridis")  #packages
packs <- installed.packages()   # find installed package list
install.me <- mypacks[!(mypacks %in% packs[,"Package"])]  #what needs to be installed?
if (length(install.me) >= 1) install.packages(install.me, repos = "http://cran.us.r-project.org")   # install (if needed)
lapply(mypacks, library, character.only=TRUE)  # load all packages
```

```{r}
#install.packages("quantmod")
#library(quantmod)
```

```{r}
#Fixed Inputs
stock_list <- c("TSLA", "TM", "POAHY", "VWAPY", "MBGAF", "GM", "F", "BMWYY", "STLA", "HMC", "RACE", "RIVN", "HYMTF", "NIO", "LCID", "TTM", "NSANY", "VLVLY")
from_date <- "2022-6-26"
to_date <- "2022-8-15"
#Adjust this to a week: how to figure out the internal
#Calculate the returns. Average and plot them on the same figure --> smoother in ggplot 
#Instead of just before and after: dummies for each day. Group, Each Day, Interaction between Group and Each Day
#Calculating the difference between each graph on a daily basis 
#Rerun with three data points
#Start with daily one
#Ideally the stock returns are flat before and then it jumps up in group 1
#If its not flat before...you worry its not a good control group
#Change the graph to returns because closing price is misleading
#If you plot them together, they should be on top of each other until the event
#Create 30 before and after 
#Consider changing the date to a day before if you think there is an anticipate --> if it is obvious in the data you can make this case 
#Group, 60 dummies, 60 dummies * group interaction = 121
frequency <- "daily"

TwoModels <- c("TSLA","GM","F", "HMC")
OneModel <- c("VWAPY","NSANY")
ZeroModels <- c("TM", "POAHY", "MBGAF", "BMWYY", "STLA", "RACE", "RIVN", "HYMTF", "NIO", "LCID", "TTM", "VLVLY")
#Something is odd with Porsche via Pitchbook
#Added Volvo VLVLY
```


```{r}
master_df = NULL
for (idx in seq(length(stock_list))){
  stock_index = stock_list[idx] #try putting this directly into the function...
  getSymbols(stock_index, src = "yahoo",from=from_date,to=to_date,frequency=frequency)
  temp_df = as.data.frame(get(stock_index))
  temp_df$Date = row.names(temp_df)
  temp_df$Index = stock_index
  row.names(temp_df) = NULL
  colnames(temp_df) = c("Open", "High", "Low", "Close", 
                        "Volume", "Adjusted", "Date", "Index")
  temp_df = temp_df[c("Date", "Index", "Open","Close")]
  
  #Adding Difference & Percent Change to master_df 
  temp_df <- temp_df %>% 
    mutate(Difference=Open-Close) %>% 
    mutate(PercentChange=Difference/Close)

  master_df = rbind(master_df, temp_df)
  
  if (stock_index=="F"){
    F_df <- temp_df
  }
  if (stock_index=="GM"){
    GM_df <- temp_df
  }
  if (stock_index=="TSLA"){
    TSLA_df <- temp_df
  }
  if (stock_index=="POAHY"){
     POAHY_df <- temp_df
  }
  if (stock_index=="VWAPY"){
     VWAPY_df <- temp_df
  }
  if (stock_index=="MBGYY"){
     MBGYY_df <- temp_df
  }
  if (stock_index=="BMWYY"){
     BMWYY_df <- temp_df
  }
  if (stock_index=="STLA"){
     STLA_df <- temp_df
  }
  if (stock_index=="HMC"){
     HMC_df <- temp_df
  }
  if (stock_index=="RACE"){
    RACE_df <- temp_df
  }
  if (stock_index=="RIVN"){
    RIVN_df <- temp_df
  }
  if (stock_index=="HYMTF"){
    HYMTF_df <- temp_df
  }
  if (stock_index=="NIO"){
    NIO_df <- temp_df
  }
  if (stock_index=="LCID"){
    LCID_df <- temp_df
  }
  if (stock_index=="TTM"){
    TTM_df <- temp_df
  }
  if (stock_index=="NSANY"){
    NSANY_df <- temp_df
  }
}
#How would I do the above in a more efficient way? i.e., not have so many if statements and then have to rbind in the following code block?
```

```{r}
#Cleaning up the dates column
master_df$Date <- ymd(master_df$Date) #To convert Date column from characters to dates 
master_df$DateForGraphs <-format(master_df$Date, format="%m-%d") #Only for data visualization purposes
master_df = master_df[c("Date","DateForGraphs","Index","Open","Close","Difference","PercentChange")] #reordering the columns
```

```{r}
#Adding Groupings (not necessary at the moment but might be helpful for cleaning code later)
master_df <- master_df %>% 
  mutate(Group = case_when(Index %in% TwoModels ~ 1, Index %in% OneModel ~ 1, Index %in% ZeroModels ~ 0)) %>%
    filter(Index != "RACE") #Filter out RACE

#Creating a column for if the date was before (0) July 27th or after (1): announcement
master_df$AfterEvent0 = ifelse(master_df$Date >= as.Date('2022-07-27'), 1, 0)
#same but for event 1: Sinema
master_df$AfterEvent1 = ifelse(master_df$Date >= as.Date('2022-08-04'), 1, 0)
#same but for event 2: law signed
master_df$AfterEvent2 = ifelse(master_df$Date >= as.Date('2022-08-16'), 1, 0)

#Creating an interaction term between AfterEvent0 and Group
master_df$GroupxAfterEvent0 = master_df$AfterEvent0 * master_df$Group

#Creating an interaction term between AfterEvent1 and Group
master_df$GroupxAfterEvent1 = master_df$AfterEvent1 * master_df$Group

#Creating an interaction term between AfterEvent2 and Group
master_df$GroupxAfterEvent2 = master_df$AfterEvent2 * master_df$Group

#Lag Close Price
master_df <- master_df %>% 
  mutate(LagClose = lag(Close))

#Difference between current day and prior day closing price
master_df <- master_df %>% 
  mutate(Returns = (Close - LagClose)/LagClose)

master_df
```

```{r}
#Creating dummy variables
master_df$N30 = ifelse(master_df$Date == as.Date('2022-06-27'), 1, 0)
master_df$N29 = ifelse(master_df$Date == as.Date('2022-06-28'), 1, 0)
master_df$N28 = ifelse(master_df$Date == as.Date('2022-06-29'), 1, 0)
master_df$N27 = ifelse(master_df$Date == as.Date('2022-06-30'), 1, 0)
master_df$N26 = ifelse(master_df$Date == as.Date('2022-07-01'), 1, 0)
master_df$N25 = ifelse(master_df$Date == as.Date('2022-07-02'), 1, 0)
master_df$N24 = ifelse(master_df$Date == as.Date('2022-07-03'), 1, 0)
master_df$N23 = ifelse(master_df$Date == as.Date('2022-07-04'), 1, 0)
master_df$N22 = ifelse(master_df$Date == as.Date('2022-07-05'), 1, 0)
master_df$N21 = ifelse(master_df$Date == as.Date('2022-07-06'), 1, 0)
master_df$N20 = ifelse(master_df$Date == as.Date('2022-07-07'), 1, 0)
master_df$N19 = ifelse(master_df$Date == as.Date('2022-07-08'), 1, 0)
master_df$N18 = ifelse(master_df$Date == as.Date('2022-07-09'), 1, 0)
master_df$N17 = ifelse(master_df$Date == as.Date('2022-07-10'), 1, 0)
master_df$N16 = ifelse(master_df$Date == as.Date('2022-07-11'), 1, 0)
master_df$N15 = ifelse(master_df$Date == as.Date('2022-07-12'), 1, 0)
master_df$N14 = ifelse(master_df$Date == as.Date('2022-07-13'), 1, 0)
master_df$N13 = ifelse(master_df$Date == as.Date('2022-07-14'), 1, 0)
master_df$N12 = ifelse(master_df$Date == as.Date('2022-07-15'), 1, 0)
master_df$N11 = ifelse(master_df$Date == as.Date('2022-07-16'), 1, 0)
master_df$N10 = ifelse(master_df$Date == as.Date('2022-07-17'), 1, 0)
master_df$N09 = ifelse(master_df$Date == as.Date('2022-07-18'), 1, 0)
master_df$N08 = ifelse(master_df$Date == as.Date('2022-07-19'), 1, 0)
master_df$N07 = ifelse(master_df$Date == as.Date('2022-07-20'), 1, 0)
master_df$N06 = ifelse(master_df$Date == as.Date('2022-07-21'), 1, 0)
master_df$N05 = ifelse(master_df$Date == as.Date('2022-07-22'), 1, 0)
master_df$N04 = ifelse(master_df$Date == as.Date('2022-07-23'), 1, 0)
master_df$N03 = ifelse(master_df$Date == as.Date('2022-07-24'), 1, 0)
master_df$N02 = ifelse(master_df$Date == as.Date('2022-07-25'), 1, 0)
master_df$N01 = ifelse(master_df$Date == as.Date('2022-07-26'), 1, 0)
master_df$Event0 = ifelse(master_df$Date == as.Date('2022-07-27'), 1, 0)
master_df$P01 = ifelse(master_df$Date == as.Date('2022-07-28'), 1, 0)
master_df$P02 = ifelse(master_df$Date == as.Date('2022-07-29'), 1, 0)
master_df$P03 = ifelse(master_df$Date == as.Date('2022-07-30'), 1, 0)
master_df$P04 = ifelse(master_df$Date == as.Date('2022-07-31'), 1, 0)
master_df$P05 = ifelse(master_df$Date == as.Date('2022-08-01'), 1, 0)
master_df$P06 = ifelse(master_df$Date == as.Date('2022-08-02'), 1, 0)
master_df$P07 = ifelse(master_df$Date == as.Date('2022-08-03'), 1, 0)
master_df$Event1 = ifelse(master_df$Date == as.Date('2022-08-04'), 1, 0)
master_df$P09 = ifelse(master_df$Date == as.Date('2022-08-05'), 1, 0)
master_df$P10 = ifelse(master_df$Date == as.Date('2022-08-06'), 1, 0)
master_df$P11 = ifelse(master_df$Date == as.Date('2022-08-07'), 1, 0)
master_df$P12 = ifelse(master_df$Date == as.Date('2022-08-08'), 1, 0)
master_df$P13 = ifelse(master_df$Date == as.Date('2022-08-09'), 1, 0)
master_df$P14 = ifelse(master_df$Date == as.Date('2022-08-10'), 1, 0)
master_df$P15 = ifelse(master_df$Date == as.Date('2022-08-11'), 1, 0)
master_df$Event2 = ifelse(master_df$Date == as.Date('2022-08-12'), 1, 0)
master_df$P17 = ifelse(master_df$Date == as.Date('2022-08-13'), 1, 0)
master_df$P18 = ifelse(master_df$Date == as.Date('2022-08-14'), 1, 0)
master_df$P19 = ifelse(master_df$Date == as.Date('2022-08-15'), 1, 0)
master_df$P20 = ifelse(master_df$Date == as.Date('2022-08-16'), 1, 0)
master_df$P21 = ifelse(master_df$Date == as.Date('2022-08-17'), 1, 0)
master_df$P22 = ifelse(master_df$Date == as.Date('2022-08-18'), 1, 0)
master_df$P23 = ifelse(master_df$Date == as.Date('2022-08-19'), 1, 0)
master_df$P24 = ifelse(master_df$Date == as.Date('2022-08-20'), 1, 0)
master_df$P25 = ifelse(master_df$Date == as.Date('2022-08-21'), 1, 0)
master_df$P26 = ifelse(master_df$Date == as.Date('2022-08-22'), 1, 0)
master_df$P27 = ifelse(master_df$Date == as.Date('2022-08-23'), 1, 0)
master_df$P28 = ifelse(master_df$Date == as.Date('2022-08-24'), 1, 0)
master_df$P29 = ifelse(master_df$Date == as.Date('2022-08-25'), 1, 0)
master_df$P30 = ifelse(master_df$Date == as.Date('2022-08-26'), 1, 0)
master_df$P31 = ifelse(master_df$Date == as.Date('2022-08-27'), 1, 0)
master_df$P32 = ifelse(master_df$Date == as.Date('2022-08-28'), 1, 0)
master_df$P33 = ifelse(master_df$Date == as.Date('2022-08-29'), 1, 0)
master_df$P34 = ifelse(master_df$Date == as.Date('2022-08-30'), 1, 0)
master_df$P35 = ifelse(master_df$Date == as.Date('2022-08-31'), 1, 0)
master_df$P36 = ifelse(master_df$Date == as.Date('2022-09-01'), 1, 0)
master_df$P37 = ifelse(master_df$Date == as.Date('2022-09-02'), 1, 0)
master_df$P38 = ifelse(master_df$Date == as.Date('2022-09-03'), 1, 0)
master_df$P39 = ifelse(master_df$Date == as.Date('2022-09-04'), 1, 0)
master_df$P40 = ifelse(master_df$Date == as.Date('2022-09-05'), 1, 0)
master_df$P41 = ifelse(master_df$Date == as.Date('2022-09-06'), 1, 0)
master_df$P42 = ifelse(master_df$Date == as.Date('2022-09-07'), 1, 0)
master_df$P43 = ifelse(master_df$Date == as.Date('2022-09-08'), 1, 0)
master_df$P44 = ifelse(master_df$Date == as.Date('2022-09-09'), 1, 0)
master_df$P45 = ifelse(master_df$Date == as.Date('2022-09-10'), 1, 0)
master_df$P46 = ifelse(master_df$Date == as.Date('2022-09-11'), 1, 0)
master_df$P47 = ifelse(master_df$Date == as.Date('2022-09-12'), 1, 0)

#NEXT I NEED TO MAKE INTERACTION TERMS
master_df$GroupxN30 = master_df$N30 * master_df$Group
master_df$GroupxN29 = master_df$N29 * master_df$Group
master_df$GroupxN28 = master_df$N28 * master_df$Group
master_df$GroupxN27 = master_df$N27 * master_df$Group
master_df$GroupxN26 = master_df$N26 * master_df$Group
master_df$GroupxN25 = master_df$N25 * master_df$Group
master_df$GroupxN24 = master_df$N24 * master_df$Group
master_df$GroupxN23 = master_df$N23 * master_df$Group
master_df$GroupxN22 = master_df$N22 * master_df$Group
master_df$GroupxN21 = master_df$N21 * master_df$Group
master_df$GroupxN20 = master_df$N20 * master_df$Group
master_df$GroupxN19 = master_df$N19 * master_df$Group
master_df$GroupxN18 = master_df$N18 * master_df$Group
master_df$GroupxN17 = master_df$N17 * master_df$Group
master_df$GroupxN16 = master_df$N16 * master_df$Group
master_df$GroupxN15 = master_df$N15 * master_df$Group
master_df$GroupxN14 = master_df$N14 * master_df$Group
master_df$GroupxN13 = master_df$N13 * master_df$Group
master_df$GroupxN12 = master_df$N12 * master_df$Group
master_df$GroupxN11 = master_df$N11 * master_df$Group
master_df$GroupxN10 = master_df$N10 * master_df$Group
master_df$GroupxN09 = master_df$N09 * master_df$Group
master_df$GroupxN08 = master_df$N08 * master_df$Group
master_df$GroupxN07 = master_df$N07 * master_df$Group
master_df$GroupxN06 = master_df$N06 * master_df$Group
master_df$GroupxN05 = master_df$N05 * master_df$Group
master_df$GroupxN04 = master_df$N04 * master_df$Group
master_df$GroupxN03 = master_df$N03 * master_df$Group
master_df$GroupxN02 = master_df$N02 * master_df$Group
master_df$GroupxN01 = master_df$N01 * master_df$Group
master_df$GroupxEvent0 = master_df$Event0 * master_df$Group
master_df$GroupxP01 = master_df$P01 * master_df$Group
master_df$GroupxP02 = master_df$P02 * master_df$Group
master_df$GroupxP03 = master_df$P03 * master_df$Group
master_df$GroupxP04 = master_df$P04 * master_df$Group
master_df$GroupxP05 = master_df$P05 * master_df$Group
master_df$GroupxP06 = master_df$P06 * master_df$Group
master_df$GroupxP07 = master_df$P07 * master_df$Group
master_df$GroupxEvent1 = master_df$Event1 * master_df$Group
master_df$GroupxP09 = master_df$P09 * master_df$Group
master_df$GroupxP10 = master_df$P10 * master_df$Group
master_df$GroupxP11 = master_df$P11 * master_df$Group
master_df$GroupxP12 = master_df$P12 * master_df$Group
master_df$GroupxP13 = master_df$P13 * master_df$Group
master_df$GroupxP14 = master_df$P14 * master_df$Group
master_df$GroupxP15 = master_df$P15 * master_df$Group
master_df$GroupxEvent2 = master_df$Event2 * master_df$Group
master_df$GroupxP17 = master_df$P17 * master_df$Group
master_df$GroupxP18 = master_df$P18 * master_df$Group
master_df$GroupxP19 = master_df$P19 * master_df$Group
master_df$GroupxP20 = master_df$P20 * master_df$Group
master_df$GroupxP21 = master_df$P21 * master_df$Group
master_df$GroupxP22 = master_df$P22 * master_df$Group
master_df$GroupxP23 = master_df$P23 * master_df$Group
master_df$GroupxP24 = master_df$P24 * master_df$Group
master_df$GroupxP25 = master_df$P25 * master_df$Group
master_df$GroupxP26 = master_df$P26 * master_df$Group
master_df$GroupxP27 = master_df$P27 * master_df$Group
master_df$GroupxP28 = master_df$P28 * master_df$Group
master_df$GroupxP29 = master_df$P29 * master_df$Group
master_df$GroupxP30 = master_df$P30 * master_df$Group
master_df$GroupxP31 = master_df$P31 * master_df$Group
master_df$GroupxP32 = master_df$P32 * master_df$Group
master_df$GroupxP33 = master_df$P33 * master_df$Group
master_df$GroupxP34 = master_df$P34 * master_df$Group
master_df$GroupxP35 = master_df$P35 * master_df$Group
master_df$GroupxP36 = master_df$P36 * master_df$Group
master_df$GroupxP37 = master_df$P37 * master_df$Group
master_df$GroupxP38 = master_df$P38 * master_df$Group
master_df$GroupxP39 = master_df$P39 * master_df$Group
master_df$GroupxP40 = master_df$P40 * master_df$Group
master_df$GroupxP41 = master_df$P41 * master_df$Group
master_df$GroupxP42 = master_df$P42 * master_df$Group
master_df$GroupxP43 = master_df$P43 * master_df$Group
master_df$GroupxP44 = master_df$P44 * master_df$Group
master_df$GroupxP45 = master_df$P45 * master_df$Group
master_df$GroupxP46 = master_df$P46 * master_df$Group
master_df$GroupxP47 = master_df$P47 * master_df$Group

master_df
```

```{r}
#The reason why the first data point in my graph was always super high (no matter where we started) is because the first Returns for Toyota pulls Tesla's last LagClose. To prevent this, we need to filter the first date in the data set.
master_df <- master_df %>% 
  filter(Date > '2022-6-27') %>%
  mutate_at('Group', as.character)
master_df

ggplot(master_df, aes(x=Date, y=Returns, group=Group, color=Group)) + geom_line() + ylim(-0.25,0.25) + labs(x="Date", y="Stock Returns") + ggtitle("Stock Returns For Qualified and Unqualified Groups") +scale_color_discrete(labels=c('Unqualified','Qualified')) 

#If I can scale these manually that would be preferred
#Figure out what is wrong with that first data point
```

```{r}
#Diff-in-Diff Regression
didreg1 = lm(Returns ~ AfterEvent0 + Group + GroupxAfterEvent0 + GroupxAfterEvent1 + GroupxAfterEvent2 +N30+N29+N28+N27+N26+N25+N24+N23+N22+N21+N20+N19+N18+N17+N16+N15+N14+N13+N12+N11+N10+N09+N08+N07+N06+N05+N04+N03+N02+N01+Event0+P01+P02+P03+P04+P05+P06+P07+Event1+P09+P10+P11+P12+P13+P14+P15+Event2+P17+P18+P19+P20+P17+P18+P19+P20+P21+P22+P23+P24+P25+P26+P27+P28+P29+P30+P31+P32+P33+P34+P35+P36+P37+P38+P39+P40+P41+P42+P43+P44+P45+P46+P47, data = master_df) 
summary(didreg1) #Review the results 
#What other features should I include?
```


```{r}
#Making qualified (1 or 2 models) df and disqualified (0 models) df
Disqualified_df <- master_df %>%
  filter(Group==0)

Disqualified_df

Qualified_df <- master_df %>%
  filter(Group==1)

Qualified_df
```

```{r}
Disqualified_df %>%
    group_by(Index) %>%
    plot_time_series(Date, Returns,
                     .facet_ncol  = 3,     # 3-column layout
                     .interactive = FALSE, .title="Closing Price for Disqualified Automakers (faceted by index)")

sp <- Qualified_df %>%
    group_by(Index) %>%
    plot_time_series(Date, Returns,
                     .facet_ncol  = 3,     # 3-column layout
                     .interactive = FALSE, .title="Closing Price for Qualified Automakers (faceted by index)") 

sp + geom_vline(xintercept = 2022-07-27, linetype="dotted", color = "red", size=1.5)
```


```{r}
#Averaging along all indexes
Mean_Disqualified_df = Disqualified_df[c("Date","Open","Close","Difference","PercentChange", "Returns")] 
Mean_Disqualified_df <- aggregate(Mean_Disqualified_df, by = list(Disqualified_df$Date), FUN = mean)
Mean_Qualified_df = Qualified_df[c("Date","Open","Close","Difference","PercentChange", "Returns")]
Mean_Qualified_df <- aggregate(Mean_Qualified_df, by = list(Qualified_df$Date), FUN = mean)
```

```{r}
Mean_Disqualified_df
Mean_Qualified_df
#HOW DO I CHECK THAT THIS ACCURATELY CALCULATED THE MEAN?
```


```{r}
Mean_Disqualified_df %>%
  plot_time_series(Date, Returns, .interactive=FALSE, .title="Mean Returns for Disqualified Automakers", .x_lab="Date", .y_lab="Average Closing Price")
Mean_Qualified_df %>%
  plot_time_series(Date, Returns, .interactive=FALSE, .title="Mean Returns for Qualified Automakers", .x_lab="Date", .y_lab="Average Closing Price")

#add dots? Standard deviation?
#Get an R Squared...how well dots fit the data set
```
  
```{r}
#we now have some graphs averaged by group and it looks like the effect is minimal
#so now I need to run a regression to prove this and then I can talk about the reasons for this
#1) it is possible that no company will qualify, especially when the China rule goes into effect. We really don't know yet. Company announcements about their supply chain will give us a better indication on whether they can qualify.
#2) Some of these vehicles are too expensive
#3)

#Create the linear regression with Group(0 or 1) as dummy variable
lmHeight = lm(Returns~Group, data = master_df) 
summary(lmHeight) #Review the results
#What other features should I include?
#How do I make this a difference-in-difference approach and focus on the treatment date (announcement July 27th)?
#What summary statistics should I include?
```
  
```{r}
#Not sure what this is or how it might be helpful...
master_df %>%
    group_by(Group) %>%
    plot_time_series_regression(
        .date_var     = Date,
        .formula      = Difference ~ as.numeric(Date),
        .facet_ncol   = 2,
        .interactive  = FALSE,
        .show_summary = FALSE
    )
```
  
```{r, eval=FALSE}
#Old inefficient code approach
if(FALSE){
  #Creating an TwoModel_df
  TwoModels_df = rbind(F_df, GM_df, TSLA_df)
  TwoModels_df$Date <- ymd(TwoModels_df$Date)
  TwoModels_df$DateForGraphs <-format(TwoModels_df$Date, format="%m-%d")
  TwoModels_df = TwoModels_df[c("Date","Open","Close","Difference","PercentChange")] 
  
  #Creating a OneModel_df
  OneModel_df = rbind(VWAPY_df,NSANY_df)
  OneModel_df$Date <- ymd(OneModel_df$Date)
  OneModel_df$DateForGraphs <-format(OneModel_df$Date, format="%m-%d")
  OneModel_df = OneModel_df[c("Date","Open","Close","Difference","PercentChange")] #removed Index
  
  #Creating an F_df. This has to occur after the above TwoModels_df code
  F_df$Date <- ymd(F_df$Date)
  F_df$DateForGraphs <-format(F_df$Date, format="%m-%d")
  F_df = F_df[c("Date","Open","Close","Difference","PercentChange")]  #removed Index
  
  #Creating a ZeroModel_df
  ZeroModel_df = rbind(POAHY_df,MBGYY_df,BMWYY_df,STLA_df,HMC_df,RACE_df,RIVN_df,HYMTF_df,NIO_df,LCID_df,TTM_df)
  ZeroModel_df$Date <- ymd(ZeroModel_df$Date)
  ZeroModel_df$DateForGraphs <-format(ZeroModel_df$Date, format="%m-%d")
  ZeroModel_df = ZeroModel_df[c("Date","Open","Close","Difference","PercentChange")] #removed Index
  
  OneOrMoreModels_df = rbind(TwoModels_df,OneModel_df)
  
  #Averaging along all indexes in a group(0 models or 1/2 models)
  ZeroModel_df_group_mean <- aggregate(ZeroModel_df, by = list(ZeroModel_df$Date), FUN = mean)
  OneOrMoreModels_df_group_mean <- aggregate(OneOrMoreModels_df, by = list(OneOrMoreModels_df$Date), FUN = mean)
  
  ZeroModel_df_group_mean
  OneOrMoreModels_df_group_mean
  ZeroModel_df_group_mean %>%
    plot_time_series(Date, Close, .interactive=FALSE)
  OneOrMoreModels_df_group_mean %>%
    plot_time_series(Date, Close, .interactive=FALSE)
}
```


```{r}
ggplot(master_df, aes(x=Date,y=PercentChange)) + geom_point(aes(color=Index)) + labs(x="Date",y="Close")
#Ideas: add a vertical line for the dates of interest
#Color code companies based on their group: Group 1, Group 2, Group 3
```

```{r}
#I need to figure out how to make this graph accommodate multiple indexes
F_df %>%
  plot_time_series(Date, Close, .interactive=FALSE)
```


```{r}
#.interactive=TRUE makes it an interactive visualization based on Plotly library
F_df %>%
  plot_time_series(Date, Close, .interactive=TRUE, .plotly_slider=TRUE)
```

```{r}
TwoModels_df %>%
  group_by(Index) %>%
  plot_time_series(Date, Close, .facet_scales="free", .smooth=FALSE, .interactive=FALSE)

#Should I create a df that averages 2Model, 1Model, 0Models? Or American versus nonAmerican?
```

```{r}
OneModel_df %>%
  group_by(Index) %>%
  plot_time_series(Date, Close, .facet_scales="free", .smooth=FALSE, .interactive=FALSE)
```

```{r}
ZeroModel_df %>%
  group_by(Index) %>%
  plot_time_series(Date, Close, .facet_scales="free", .smooth=FALSE, .interactive=FALSE)
```

```{r}
#average return on each day 1or2 versus 0, plot the key date lines, and see if there looks like an impact

#Daily data --> simple regression 
#dummy variable: 1 if after; 0 if before
#dummy variable: 1 = 1 or 2 models, 0 = 0 models
#interaction (if pos=effect)

#different specification for each of the three important

#Other:
#Fix graph axis
#Summary statistics?
```

```{r}
#Anomaly Analysis

#How would I run this with multiple companys????
# Get data
F_df %>%
  # Group the data by Index
  group_by(Index) %>%
  # Visualize 
  plot_anomaly_diagnostics(Date, Close)

#gathering all anomaly data into a new df
anomaly_data <- F_df %>%
  group_by(Index) %>%
  tk_anomaly_diagnostics(Date, Close) %>%
  filter(anomaly == 'Yes')
View(anomaly_data)
```



## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
getSymbols("TSLA", from="2022-7-27", to="2022-9-4", periodicity="daily", src="yahoo")
#quantmod's getSymbols function only works with daily, weekly, and monthly
chartSeries(TSLA, theme=chartTheme("white"))
#addMACD() What does this line do?
summary(cars)
```
```{r}

#ticker <- "GM"
#date_from <- "2022-7-27"
#date_to <- "2022-9-4"
#frequency <- "daily"

StockDataIteration <- function(ticker, date_from, date_to, frequency)
{
  getSymbols(ticker, from=date_from, to=date_to, periodicity=frequency, src="yahoo")
  chart <- chartSeries(ticker, theme=chartTheme("white"))
  return(chart)

}
```

```{r}
StockDataIteration("GM","2022-7-27","2022-9-4","daily")
#Need to do some research on writing functions in R
#Need to then create a for loop where all of this data is added to a datatable as a new column
```



Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
